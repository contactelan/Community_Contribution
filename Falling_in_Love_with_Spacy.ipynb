{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcD0hL_qW9p4"
   },
   "source": [
    "spaCy is an advanced modern library for Natural Language Processing developed by Matthew Honnibal and Ines Montani. It is designed to be industrial grade but open source.\n",
    "\n",
    "spaCy comes with pretrained NLP models that can perform most common NLP tasks, such as tokenization, parts of speech (POS) tagging, named entity recognition (NER), lemmatization, transforming to word vectors etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "wBC8mxhrW07t",
    "outputId": "1dfef411-1a9e-4ffc-d230-0e86d284eb46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f91a6ba1e48>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "# Load small english model: https://spacy.io/models\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DE7ldpF7XnGx"
   },
   "source": [
    "First, call the loaded nlp object on the text. It should return a processed Doc object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "R5uP8AmxXP05",
    "outputId": "e8944dde-4303-4af4-efa7-290a8808585a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse text through the `nlp` model\n",
    "my_text = \"\"\"The economic situation of the country is on edge , as the stock \n",
    "market crashed causing loss of millions. Citizens who had their main investment \n",
    "in the share-market are facing a great loss. Many companies might lay off \n",
    "thousands of people to reduce labor cost\"\"\"\n",
    "\n",
    "my_doc = nlp(my_text)\n",
    "type(my_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3VdyRuuYWW_"
   },
   "source": [
    "The output is a Doc object.\n",
    "\n",
    "But, what exactly is a Doc object ?\n",
    "\n",
    "It is a sequence of tokens that contains not just the original text but all the results produced by the spaCy model after processing the text. Useful information such as the lemma of the text, whether it is a stop word or not, named entities, the word vector of the text and so on are pre-computed and readily stored in the Doc object.\n",
    "\n",
    "The good thing is that you have complete control on what information needs to be pre-computed and customized. We will see all of that shortly.\n",
    "\n",
    "Also, though the text gets split into tokens, no information of the original text is actually lost.\n",
    "\n",
    "What is a Token?\n",
    "\n",
    "Tokens are individual text entities that make up the text. Typically a token can be the words, punctuation, spaces, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mgFYLGTtXPyV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfADYUGecTji"
   },
   "source": [
    "**What is Tokenization?**\n",
    "\n",
    "> Indented block\n",
    "\n",
    "\n",
    "\n",
    "Tokenization is the process of converting a text into smaller sub-texts, based on certain predefined rules. For example, sentences are tokenized to words (and punctuation optionally). And paragraphs into sentences, depending on the context.\n",
    "\n",
    "This is typically the first step for NLP tasks like text classification, sentiment analysis, etc.\n",
    "\n",
    "Each token in spacy has different attributes that tell us a great deal of information.\n",
    "\n",
    "Such as, if the token is a punctuation, what part-of-speech (POS) is it, what is the lemma of the word etc. This article will cover everything from A-Z.\n",
    "\n",
    "Let’s see the token texts on my_doc. The string which the token represents can be accessed through the token.text attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "id": "piwZvLSnXPwb",
    "outputId": "d2a957c7-167a-447b-c811-0763d58053c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "economic\n",
      "situation\n",
      "of\n",
      "the\n",
      "country\n",
      "is\n",
      "on\n",
      "edge\n",
      ",\n",
      "as\n",
      "the\n",
      "stock\n",
      "\n",
      "\n",
      "market\n",
      "crashed\n",
      "causing\n",
      "loss\n",
      "of\n",
      "millions\n",
      ".\n",
      "Citizens\n",
      "who\n",
      "had\n",
      "their\n",
      "main\n",
      "investment\n",
      "\n",
      "\n",
      "in\n",
      "the\n",
      "share\n",
      "-\n",
      "market\n",
      "are\n",
      "facing\n",
      "a\n",
      "great\n",
      "loss\n",
      ".\n",
      "Many\n",
      "companies\n",
      "might\n",
      "lay\n",
      "off\n",
      "\n",
      "\n",
      "thousands\n",
      "of\n",
      "people\n",
      "to\n",
      "reduce\n",
      "labor\n",
      "cost\n"
     ]
    }
   ],
   "source": [
    "# Printing the tokens of a doc\n",
    "for token in my_doc:\n",
    "  print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "dwjN87rVXPsZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7pPl2B4coE2"
   },
   "source": [
    "What is the need for Text Preprocessing ?\n",
    "\n",
    "The outcome of the NLP task you perform, be it classification, finding sentiments, topic modeling etc, the quality of the output depends heavily on the quality of the input text used.\n",
    "\n",
    "Stop words and punctuation usually (not always) don’t add value to the meaning of the text and can potentially impact the outcome. To avoid this, its might make sense to remove them and clean the text of unwanted characters can reduce the size of the corpus.\n",
    "\n",
    "How to identify and remove the stopwords and punctuation?\n",
    "\n",
    "The tokens in spacy have attributes which will help you identify if it is a stop word or not.\n",
    "\n",
    "The token.is_stop attribute tells you that. Likewise, token.is_punct and token.is_space tell you if a token is a punctuation and white space respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "id": "R9d5lgZ8XPqi",
    "outputId": "a0af3b82-65cc-4a7e-d91f-49e46b97ba68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "economic\n",
      "situation\n",
      "country\n",
      "edge\n",
      "stock\n",
      "\n",
      "\n",
      "market\n",
      "crashed\n",
      "causing\n",
      "loss\n",
      "millions\n",
      "Citizens\n",
      "main\n",
      "investment\n",
      "\n",
      "\n",
      "share\n",
      "market\n",
      "facing\n",
      "great\n",
      "loss\n",
      "companies\n",
      "lay\n",
      "\n",
      "\n",
      "thousands\n",
      "people\n",
      "reduce\n",
      "labor\n",
      "cost\n"
     ]
    }
   ],
   "source": [
    "# Removing StopWords and punctuations\n",
    "my_doc_cleaned = [token for token in my_doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "for token in my_doc_cleaned:\n",
    "  print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "D22YePYeXPpO"
   },
   "outputs": [],
   "source": [
    "# Reading a huge text data on robotics into a spacy doc\n",
    "robotics_data= \"\"\"Robotics is an interdisciplinary research area at the interface of computer science and engineering. Robotics involvesdesign, construction, operation, and use of robots. The goal of robotics is to design intelligent machines that can help and assist humans in their day-to-day lives and keep everyone safe. Robotics draws on the achievement of information engineering, computer engineering, mechanical engineering, electronic engineering and others.Robotics develops machines that can substitute for humans and replicate human actions. Robots can be used in many situations and for lots of purposes, but today many are used in dangerous environments(including inspection of radioactive materials, bomb detection and deactivation), manufacturing processes, or where humans cannot survive (e.g. in space, underwater, in high heat, and clean up and containment of hazardousmaterials and radiation). Robots can take on any form but some are made to resemble humans in appearance. This is said to help in the acceptance of a robot in \n",
    "certain replicative behaviors usually performed by people. Such robots attempt to replicate walking, lifting, speech, cognition, or any other human activity. Many of todays robots are inspired by nature, contributing to the field of bio-inspired \n",
    "robotics.The concept of creating machines that can operate autonomously dates back to classical times, but research into the functionality and potential uses of robots did not grow substantially until the 20th century. Throughout history, it has been frequently assumed by various scholars, inventors, engineers, and technicians that robots will one day be able to mimic human behavior and manage tasks in a human-like fashion. Today, robotics is a rapidly growing field, as technological advances continue; researching, designing, and building new robots serve various practical purposes, whether domestically, commercially, or militarily. Many robots are built to do jobs that are hazardous to people, such as defusing bombs, finding survivors in unstable ruins, and exploring mines and shipwrecks. Robotics is also used in STEM (science, technology, engineering, and mathematics) as a teaching aid. The advent of nanorobots, microscopic robots that can be injected into the human body, could revolutionize medicine and human health.Robotics is a branch of engineering that involves the conception, design, manufacture, and operation of robots. This field overlaps with computer engineering, computer science (especially artificial intelligence), electronics, mechatronics, nanotechnology and bioengineering.The word robotics was derived from the word robot, which was introduced to the public by Czech writer Karel Capek in his play R.U.R. (Rossums Universal Robots), whichwas published in 1920. The word robot comes from the Slavic word robota, which means slave/servant. The play begins in a factory that makes artificial people called robots, creatures who can be mistaken for humans – very similar to the modern ideas of androids. Karel Capek himself did not coin the word. He wrote a short letter in reference to an etymology in the \n",
    "Oxford English Dictionary in which he named his brother Josef Capek as its actual \n",
    "originator.According to the Oxford English Dictionary, the word robotics was first \n",
    "used in print by Isaac Asimov, in his science fiction short story \"Liar!\", \n",
    "published in May 1941 in Astounding Science Fiction. Asimov was unaware that he \n",
    "was coining the term  since the science and technology of electrical devices is \n",
    "electronics, he assumed robotics already referred to the science and technology \n",
    "of robots. In some of Asimovs other works, he states that the first use of the \n",
    "word robotics was in his short story Runaround (Astounding Science Fiction, March \n",
    "1942) where he introduced his concept of The Three Laws of Robotics. However, \n",
    "the original publication of \"Liar!\" predates that of \"Runaround\" by ten months, \n",
    "so the former is generally cited as the words origin.There are many types of robots; \n",
    "they are used in many different environments and for many different uses. Although \n",
    "being very diverse in application and form, they all share three basic similarities \n",
    "when it comes to their construction:Robots all have some kind of mechanical construction, a frame, form or shape designed to achieve a particular task. For example, a robot designed to travel across heavy dirt or mud, might use caterpillar tracks. The mechanical aspect is mostly the creators solution to completing the assigned task and dealing with the physics of the environment around it. Form follows function.Robots have electrical components which power and control the machinery. For example, the robot with caterpillar tracks would need some kind of power to move the tracker treads. That power comes in the form of electricity, which will have to travel through a wire and originate from a battery, a basic electrical circuit. Even petrol powered machines that get their power mainly from petrol still require an electric current to start the combustion process which is why most petrol powered machines like cars, have batteries. The electrical aspect of robots is used for movement (through motors), sensing (where electrical signals are used to measure things like heat, sound, position, and energy status) and operation (robots need some level of electrical energy supplied to their motors and sensors in order to activate and perform basic operations) All robots contain some level of computer programming code. A program is how a robot decides when or how to do something. In the caterpillar track example, a robot that needs to move across a muddy road may have the correct mechanical construction and receive the correct amount of power from its battery, but would not go anywhere without a program telling it to move. Programs are the core essence of a robot, it could have excellent mechanical and electrical construction, but if its program is poorly constructed its performance will be very poor (or it may not perform at all). There are three different types of robotic programs: remote control, artificial intelligence and hybrid. A robot with remote control programing has a preexisting set of commands that it will only perform if and when it receives a signal from a control source, typically a human being with a remote control. It is perhaps more appropriate to view devices controlled primarily by human commands as falling in the discipline of automation rather than robotics. Robots that use artificial intelligence interact with their environment on their own without a control source, and can determine reactions to objects and problems they encounter using their preexisting programming. Hybrid is a form of programming that incorporates both AI and RC functions.As more and more robots are designed for specific tasks this method of classification becomes more relevant. For example, many robots are designed for assembly work, which may not be readily adaptable for other applications. They are termed as \"assembly robots\". For seam welding, some suppliers provide complete welding systems with the robot i.e. the welding equipment along with other material handling facilities like turntables, etc. as an integrated unit. Such an integrated robotic system is called a \"welding robot\" even though its discrete manipulator unit could be adapted to a variety of tasks. Some robots are specifically designed for heavy load manipulation, and are labeled as \"heavy-duty robots\".one or two wheels. These can have certain advantages such as greater efficiency and reduced parts, as well as allowing a robot to navigate in confined places that a four-wheeled robot would not be able to.Two-wheeled balancing robots Balancing robots generally use a gyroscope to detect how much a robot is falling and then drive the wheels proportionally in the same direction, to counterbalance the fall at hundreds of times per second, based on the dynamics of an inverted pendulum.[71] Many different balancing robots have been designed.[72] While the Segway is not commonly thought of as a robot, it can be thought of as a component of a robot, when used as such Segway refer to them as RMP (Robotic Mobility Platform). An example of this use has been as NASA Robonaut that has been mounted on a Segway.One-wheeled balancing robots Main article: Self-balancing unicycle A one-wheeled balancing robot is an extension of a two-wheeled balancing robot so that it can move in any 2D direction using a round ball as its only wheel. Several one-wheeled balancing robots have been designed recently, such as Carnegie Mellon Universitys \"Ballbot\" that is the approximate height and width of a person, and Tohoku Gakuin University BallIP Because of the long, thin shape and ability to maneuver in tight spaces, they have the potential to function better than other robots in environments with people\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "boR3y6_qXPm1",
    "outputId": "ac7f3a6e-3939-4704-a5d9-e33ff4ca5467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PreProcessing n_Tokens:  1626\n",
      "After PreProcessing n_Tokens:  744\n"
     ]
    }
   ],
   "source": [
    "# Pass the Text to Model\n",
    "robotics_doc = nlp(robotics_data)\n",
    "\n",
    "print('Before PreProcessing n_Tokens: ', len(robotics_doc))\n",
    "\n",
    "# Removing stopwords and punctuation from the doc.\n",
    "robotics_doc=[token for token in robotics_doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "print('After PreProcessing n_Tokens: ', len(robotics_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJCx5SjOdEHQ"
   },
   "source": [
    "Have a look at these words: “played”, “playing”, “plays”, “play”.\n",
    "\n",
    "These words are not entirely unique, as they all basically refer to the root word: “play”. Very often, while trying to interpret the meaning of the text using NLP, you will be concerned about the root meaning and not the tense.\n",
    "\n",
    "For algorithms that work based on the number of occurrences of the words, having multiple forms of the same word will reduce the number of counts for the root word, which is ‘play’ in this case.\n",
    "\n",
    "Hence, counting “played” and “playing” as different tokens will not help.\n",
    "\n",
    "Lemmatization is the method of converting a token to it’s root/base form.\n",
    "\n",
    "Fortunately, spaCy provides a very easy and robust solution for this and is considered as one of the optimal implementations.\n",
    "\n",
    "After you’ve formed the Document object (by using nlp()), you can access the root form of every token through Token.lemma_ attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "0wdG-xHHXPjd",
    "outputId": "ea3ac4bb-3162-4c42-d733-ab9e53fe0bcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-PRON-\n",
      "play\n",
      "chess\n",
      "against\n",
      "rita\n",
      "-PRON-\n",
      "like\n",
      "play\n",
      "chess\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Lemmatizing the tokens of a doc\n",
    "text='she played chess against rita she likes playing chess.'\n",
    "doc=nlp(text)\n",
    "for token in doc:\n",
    "  print(token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nA4n0Kt7duQ_"
   },
   "source": [
    "The spaCy model provides many useful lexical attributes. These are the attributes of Token object, that give you information on the type of token.\n",
    "\n",
    "For example, you can use like_num attribute of a token to check if it is a number. Let’s print all the numbers in a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "_iDTg4S7XPhq",
    "outputId": "051c16d3-024a-4673-e2e6-034945f8c2d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n",
      "2009\n"
     ]
    }
   ],
   "source": [
    "# Printing the tokens which are like numbers\n",
    "text=' 2020 is far worse than 2009'\n",
    "doc=nlp(text)\n",
    "for token in doc:\n",
    "  if token.like_num:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "KAFjrBRxXPeb",
    "outputId": "fdd13a45-d8b4-41d8-bd8e-e2d0d0c57771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "43\n",
      "98\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "production_text=' Production in chennai is 87 %. In Kolkata, produce it as low as 43 %. In Bangalore, production ia as good as 98 %.In mysore, production is average around 78 %'\n",
    "\n",
    "# Finding the tokens which are numbers followed by % \n",
    "\n",
    "production_doc=nlp(production_text)\n",
    "\n",
    "for token in production_doc:\n",
    "  if token.like_num:\n",
    "    index_of_next_token=token.i+ 1\n",
    "    next_token=production_doc[index_of_next_token]\n",
    "    if next_token.text == '%':\n",
    "      print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbuwzmFyeBqS"
   },
   "source": [
    "What if you want all the emails of employees to send a common email ?\n",
    "\n",
    "You can tokenize the document and check which tokens are emails through like_email attribute. like_email returns True if the token is a email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "L_Q2NKDUXPc0",
    "outputId": "47845266-d910-4a60-ed6a-3af425247f45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "koushiki@gmail.com\n",
      "gayathri1999@gmail.com\n",
      "ardra@gmail.com\n",
      "parmar15@yahoo.com\n",
      "shank@rediffmail.com\n",
      "utkarsh@gmail.com\n"
     ]
    }
   ],
   "source": [
    "# text containing employee details\n",
    "employee_text=\"\"\" name : Koushiki age: 45 email : koushiki@gmail.com\n",
    "                 name : Gayathri age: 34 email: gayathri1999@gmail.com\n",
    "                 name : Ardra age: 60 email : ardra@gmail.com\n",
    "                 name : pratham parmar age: 15 email : parmar15@yahoo.com\n",
    "                 name : Shashank age: 54 email: shank@rediffmail.com\n",
    "                 name : Utkarsh age: 46 email :utkarsh@gmail.com\"\"\"\n",
    "\n",
    "# creating a spacy doc          \n",
    "employee_doc=nlp(employee_text)\n",
    "\n",
    "# Printing the tokens which are email through `like_email` attribute\n",
    "for token in employee_doc:\n",
    "  if token.like_email:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kr6I75XUebRX"
   },
   "source": [
    "Consider a sentence , “Emily likes playing football”.\n",
    "\n",
    "Here , Emily is a NOUN , and playing is a VERB. Likewise , each word of a text is either a noun, pronoun, verb, conjection, etc. These tags are called as Part of Speech tags (POS).\n",
    "\n",
    "How to identify the part of speech of the words in a text document ?\n",
    "\n",
    "It is present in the pos_ attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "k1PqXLW7XPaV",
    "outputId": "c4bf4fbf-12fa-46aa-f685-c8f3c83c2f31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John ----  PROPN\n",
      "plays ----  VERB\n",
      "basketball ----  NOUN\n",
      ", ----  PUNCT\n",
      "if ----  SCONJ\n",
      "time ----  NOUN\n",
      "permits ----  VERB\n",
      ". ----  PUNCT\n",
      "He ----  PRON\n",
      "played ----  VERB\n",
      "in ----  ADP\n",
      "high ----  ADJ\n",
      "school ----  NOUN\n",
      "too ----  ADV\n",
      ". ----  PUNCT\n"
     ]
    }
   ],
   "source": [
    "# POS tagging using spaCy\n",
    "my_text='John plays basketball,if time permits. He played in high school too.'\n",
    "my_doc=nlp(my_text)\n",
    "for token in my_doc:\n",
    "  print(token.text,'---- ',token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSkYvMg7epUZ"
   },
   "source": [
    "Consider you have a text document of reviews or comments on a post. Apart from genuine words, there will be certain junk like “etc” which do not mean anything. How can you remove them ?\n",
    "\n",
    "Using spacy’s pos_ attribute, you can check if a particular token is junk through token.pos_ == 'X' and remove them. Below code demonstrates the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "uZz5g-MaXPX9",
    "outputId": "3106b898-a710-4d46-a163-c08b87a55268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The junk values are..\n",
      "etc\n",
      "i.e.\n",
      "i.e.\n",
      "etc\n",
      "etc\n",
      "After removing junk\n",
      "[I, liked, the, movies, The, movie, had, good, direction,  , The, movie, was, amazing, \n",
      "            , The, movie, was, average, direction, was, not, bad, The, cinematography, was, nice, ., \n",
      "            , The, movie, was, a, bit, lengthy,  , otherwise, fantastic,  ]\n"
     ]
    }
   ],
   "source": [
    "# Raw text document\n",
    "raw_text=\"\"\"I liked the movies etc The movie had good direction  The movie was amazing i.e.\n",
    "            The movie was average direction was not bad The cinematography was nice. i.e.\n",
    "            The movie was a bit lengthy  otherwise fantastic  etc etc\"\"\"\n",
    "\n",
    "# Creating a spacy object\n",
    "raw_doc=nlp(raw_text)\n",
    "\n",
    "# Checking if POS tag is X and printing them\n",
    "print('The junk values are..')\n",
    "for token in raw_doc:\n",
    "  if token.pos_=='X':\n",
    "    print(token.text)\n",
    "\n",
    "print('After removing junk')\n",
    "# Removing the tokens whose POS tag is junk.\n",
    "clean_doc=[token for token in raw_doc if not token.pos_=='X']\n",
    "print(clean_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7-7CikIfMOt"
   },
   "source": [
    "For better understanding of various POS of a sentence, you can use the visualization function displacy of spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "IESBDRVsdvmr",
    "outputId": "7383f481-df6f-4b34-fd85-0622612dd8f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"d641f08f7b6545698b5368c35a4fb630-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">She</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">never</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">like</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">playing ,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">reading</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">her</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">hobby</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d641f08f7b6545698b5368c35a4fb630-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d641f08f7b6545698b5368c35a4fb630-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d641f08f7b6545698b5368c35a4fb630-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d641f08f7b6545698b5368c35a4fb630-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d641f08f7b6545698b5368c35a4fb630-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d641f08f7b6545698b5368c35a4fb630-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d641f08f7b6545698b5368c35a4fb630-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d641f08f7b6545698b5368c35a4fb630-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d641f08f7b6545698b5368c35a4fb630-0-4\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d641f08f7b6545698b5368c35a4fb630-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d641f08f7b6545698b5368c35a4fb630-0-5\" stroke-width=\"2px\" d=\"M945,177.0 C945,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d641f08f7b6545698b5368c35a4fb630-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing displacy\n",
    "from spacy import displacy\n",
    "my_text='She never like playing , reading was her hobby'\n",
    "my_doc=nlp(my_text)\n",
    "\n",
    "# displaying tokens with their POS tags\n",
    "displacy.render(my_doc,style='dep',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GldMkRMsfay4"
   },
   "source": [
    "Have a look at this text “John works at Google1″. In this, ” John ” and ” Google ” are names of a person and a company. These words are referred as named-entities. They are real-world objects like name of a company , place,etc..\n",
    "\n",
    "How can find all the named-entities in a text ?\n",
    "\n",
    "Using spaCy’s ents attribute on a document, you can access all the named-entities present in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "WNiSCN6Zdvk7",
    "outputId": "7f085e5f-a3b5-432b-9adf-65b7d3b88d4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Tony Stark, StarkEnterprises, Emily Clark, Microsoft, Manchester, Bible, French)\n"
     ]
    }
   ],
   "source": [
    "# Preparing the spaCy document\n",
    "text='Tony Stark owns the company StarkEnterprises . Emily Clark works at Microsoft and lives in Manchester. She loves to read the Bible and learn French'\n",
    "doc=nlp(text)\n",
    "\n",
    "# Printing the named entities\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaXAkRdQflL_"
   },
   "source": [
    "You can access the same through .label_ attribute of spacy. It prints the label of named entities as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "eYmUT-_NdwnY",
    "outputId": "6398e41e-d327-4a08-d8fd-0226ea441921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony Stark ---  PERSON\n",
      "StarkEnterprises ---  ORG\n",
      "Emily Clark ---  PERSON\n",
      "Microsoft ---  ORG\n",
      "Manchester ---  GPE\n",
      "Bible ---  WORK_OF_ART\n",
      "French ---  LANGUAGE\n"
     ]
    }
   ],
   "source": [
    "# Printing labels of entities.\n",
    "for entity in doc.ents:\n",
    "  print(entity.text,'--- ',entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m54AhsxwfsmB"
   },
   "source": [
    "spaCy also provides special visualization for NER through displacy. Using displacy.render() function, you can set the style=ent to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "kUWIyS_sdwwA",
    "outputId": "882e722e-3b67-4bf9-e2b6-4f65916741c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tony Stark\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " owns the company \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    StarkEnterprises\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " . \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Emily Clark\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " works at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and lives in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Manchester\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". She loves to read the \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bible\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       " and learn \n",
       "<mark class=\"entity\" style=\"background: #ff8197; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    French\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LANGUAGE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using displacy for visualizing NER\n",
    "from spacy import displacy\n",
    "displacy.render(doc,style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "_7fkC4lBdw8t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "QihDPzyXdxNa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "65bt8MtbdxTk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Uq-hsrMDdxIX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "EqPrJuu9dxFE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "0UoyPJbwdw5M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "F3y1GD3ddw33"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "9Xzvvpnldw1b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "bIfwL3pZdwrm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "46Xat1GEdwkt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Falling in Love with Spacy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
